using Base.Threads, Turing, Distributions, StatsBase, Plots, StatsPlots, MCMCChains, DataFrames, CSV, ProgressMeter

Turing.setprogress!(false)

import Logging

@model AR(x, N) = begin
    Œ± ~ Normal(0, 1)
    Œ≤ ~ Uniform(-1, 1)
    for t in 2:N
        Œº = Œ± + Œ≤ * x[t-1]
        x[t] ~ Normal(Œº, 1)
    end
end

struct ARModel
    Œ±::Float64
    Œ≤::Float64
end

function predict(model::ARModel, x‚ÇÄ, N)
    p = zeros(Float64, N + 1)
    p[1] = x‚ÇÄ
    ùí© = Normal(0, 1)
    for t in 1:N
        p[t + 1] = model.Œ± + model.Œ≤*p[t] + rand(ùí©)
    end
    p
end

function fit(data::AbstractVector{Float64}, args...; kwargs...)
    N = length(data)
    logger = Logging.SimpleLogger(stderr, Logging.Error)
    chain = Logging.with_logger(logger) do
        sample(AR(data, N), args...; kwargs...)
    end
    Œ±, Œ≤ = mean(chain[:Œ±]), mean(chain[:Œ≤])
    return ARModel(Œ±, Œ≤)
end

function fit(filename::AbstractString; thread=true)
    df = DataFrame(CSV.File(filename))

    T = length(unique(df.timestep))

    data = mapslices(zscore, reshape(df.c + df.r, T, nrow(df) √∑ T), dims=1)
    train = data[1:floor(Int, 0.9 * T), :]

    models = Array{ARModel}(undef, size(data,2))
    if thread
        Threads.@threads :static for i in 1:size(data, 2)
            models[i] = fit(train[:, i], NUTS(), 100000)
        end
    else
        @showprogress for i in 1:size(data, 2)
            models[i] = fit(train[:, i], NUTS(), 100000)
        end
    end

    models
end 
